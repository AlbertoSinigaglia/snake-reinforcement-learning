{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from helpers import re_normalize_possible_actions\n",
    "from environments import *\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from  tqdm import trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Environment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BOARD_SIZE=10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# region models\n",
    "input = K.layers.Input(shape=(BOARD_SIZE, BOARD_SIZE, 3))\n",
    "x = K.layers.Conv2D(64, (3, 3), padding=\"SAME\", activation=\"linear\", use_bias=False)(input)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.Conv2D(64, (3, 3), padding=\"SAME\", activation=\"linear\", use_bias=False)(x)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.Conv2D(64, (3, 3), padding=\"SAME\", activation=\"linear\", use_bias=False)(x)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.MaxPool2D(2)(x)\n",
    "\n",
    "x = K.layers.Conv2D(64, (2, 2), padding=\"SAME\", activation=\"linear\", use_bias=False)(x)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.Conv2D(64, (2, 2), padding=\"SAME\", activation=\"linear\", use_bias=False)(x)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.Conv2D(8, (2, 2), padding=\"SAME\", activation=\"linear\", use_bias=False)(x)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "policy = K.layers.Dense(64, activation=tf.nn.leaky_relu)(x)\n",
    "policy = K.layers.Dense(64, activation=tf.nn.leaky_relu)(policy)\n",
    "policy = K.layers.Dense(4, activation=tf.nn.softmax)(policy)\n",
    "agent = K.models.Model(inputs=input, outputs=policy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input = K.layers.Input(shape=(BOARD_SIZE, BOARD_SIZE, 3))\n",
    "x = K.layers.Conv2D(64, (3, 3), padding=\"SAME\", activation=\"linear\", use_bias=False)(input)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.Conv2D(64, (3, 3), padding=\"SAME\", activation=\"linear\", use_bias=False)(x)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.Conv2D(64, (3, 3), padding=\"SAME\", activation=\"linear\", use_bias=False)(x)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.MaxPool2D(2)(x)\n",
    "\n",
    "x = K.layers.Conv2D(64, (2, 2), padding=\"SAME\", activation=\"linear\", use_bias=False)(x)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.Conv2D(64, (2, 2), padding=\"SAME\", activation=\"linear\", use_bias=False)(x)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.Conv2D(8, (2, 2), padding=\"SAME\", activation=\"linear\", use_bias=False)(x)\n",
    "x = K.layers.BatchNormalization()(x)\n",
    "x = K.layers.Activation(tf.nn.leaky_relu)(x)\n",
    "\n",
    "x = K.layers.GlobalAvgPool2D()(x)\n",
    "\n",
    "vf = K.layers.Dense(64, activation=tf.nn.leaky_relu)(x)\n",
    "vf = K.layers.Dense(64, activation=tf.nn.leaky_relu)(vf)\n",
    "vf = K.layers.Dense(1, activation=\"linear\")(vf)\n",
    "value = K.models.Model(inputs=input, outputs=vf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    last_model_trained = sorted([ f.path for f in os.scandir(f'models/{BOARD_SIZE}x{BOARD_SIZE}/') if f.is_dir() ])[-1]\n",
    "    agent.load_weights(last_model_trained+f\"/agent\")\n",
    "    value.load_weights(last_model_trained+f\"/value\")\n",
    "    print(\"loaded\")\n",
    "except:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env_ = NumpyEnvironment(1000, BOARD_SIZE)\n",
    "env_.FRUIT_REWARD = .5\n",
    "env_.ATE_HIMSELF_REWARD = .2\n",
    "env_.WIN_REWARD = 1.\n",
    "env_.STEP_REWARD = 0.\n",
    "GAMMA = .99\n",
    "ITERATIONS = 100000\n",
    "EPSILON = 0.05"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer_value = K.optimizers.Adam(1e-4)\n",
    "optimizer_agent = K.optimizers.Adam(1e-6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_rewards = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try :\n",
    "    import json\n",
    "    with open(f\"model_fitting/trend_{BOARD_SIZE}x{BOARD_SIZE}.txt\", \"r\") as file:\n",
    "        avg_rewards = json.load(file)\n",
    "except:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for iterations in trange(ITERATIONS):\n",
    "    state = env_.to_state()\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # calculate distributions of actions\n",
    "        original_probs = agent(\n",
    "            state\n",
    "        )\n",
    "        # remove actions that are not available\n",
    "        probs = re_normalize_possible_actions(\n",
    "            state,\n",
    "            original_probs + EPSILON\n",
    "        )\n",
    "        # sample actions\n",
    "        actions = tf.random.categorical(tf.math.log(tf.stop_gradient(probs)), 1, dtype=tf.int32)\n",
    "\n",
    "        # MDP update\n",
    "        # print(\"start move\")\n",
    "        rewards = env_.move(actions)\n",
    "        # print(\"end move\")\n",
    "        new_state = env_.to_state()\n",
    "\n",
    "        # TD error\n",
    "        value_state = value(state)\n",
    "        td_error = tf.stop_gradient((rewards + GAMMA * value(new_state, training=False)) - value_state) * -1  # to do gradient ascend\n",
    "\n",
    "        # calculate the loss for both value and agent\n",
    "        actions_indexes = tf.concat((tf.range(actions.shape[0])[..., None], actions), axis=-1)\n",
    "\n",
    "        # maybe introduce eligibility trace to simulate n-step td, to have longer dependencies\n",
    "        loss_agent = tf.stop_gradient(td_error) * tf.math.log(1e-10 + tf.gather_nd(probs, actions_indexes))[...,None]\n",
    "        loss_value = tf.stop_gradient(td_error) * value_state\n",
    "\n",
    "        loss_agent = tf.reduce_mean(loss_agent)\n",
    "        loss_value = tf.reduce_mean(loss_value)\n",
    "\n",
    "    # calculate gradient\n",
    "    gradient_agent = tape.gradient(loss_agent, agent.trainable_weights)\n",
    "    gradient_value = tape.gradient(loss_value, value.trainable_weights)\n",
    "    avg_rewards.append(tf.reduce_mean(rewards))\n",
    "\n",
    "    # update neural nets weights\n",
    "    optimizer_agent.apply_gradients(zip(gradient_agent, agent.trainable_weights))\n",
    "    optimizer_value.apply_gradients(zip(gradient_value, value.trainable_weights))\n",
    "\n",
    "    if iterations % 1000 == 0:\n",
    "        now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        agent.save_weights(f\"models/{BOARD_SIZE}x{BOARD_SIZE}/{now}/agent\")\n",
    "        value.save_weights(f\"models/{BOARD_SIZE}x{BOARD_SIZE}/{now}/value\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"model_fitting/trend_{BOARD_SIZE}x{BOARD_SIZE}.txt\", \"w+\") as file:\n",
    "    json.dump(np.array(avg_rewards).tolist(), file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random policy reward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_env_ = NumpyEnvironment(1000, BOARD_SIZE)\n",
    "random_env_.FRUIT_REWARD = .5\n",
    "random_env_.ATE_HIMSELF_REWARD = .2\n",
    "random_env_.WIN_REWARD = 1.\n",
    "random_env_.STEP_REWARD = 0.\n",
    "GAMMA = .99\n",
    "ITERATIONS = 10000\n",
    "EPSILON=0.1\n",
    "random_rewards = []\n",
    "\n",
    "for _ in trange(100):\n",
    "    state = random_env_.to_state()\n",
    "    probs = re_normalize_possible_actions(\n",
    "        state,\n",
    "        tf.repeat([[.25]*4],1000, axis=0)\n",
    "    )\n",
    "    #sample actions\n",
    "    actions =  tf.random.categorical(tf.math.log(probs), 1, dtype=tf.int32)\n",
    "\n",
    "    # MDP update\n",
    "    rewards = random_env_.move(actions)\n",
    "    random_rewards.append(tf.reduce_mean(rewards))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "CHUNK_SIZE = 2000\n",
    "N = len(avg_rewards)//CHUNK_SIZE*CHUNK_SIZE\n",
    "x = np.linspace(0,CHUNK_SIZE*N, N//CHUNK_SIZE)\n",
    "plt.plot(x, np.array(random_rewards).mean(axis=-1).repeat(N//CHUNK_SIZE), marker=\"o\")\n",
    "points = np.array(avg_rewards)[:N].reshape((-1, CHUNK_SIZE)).mean(axis=-1)\n",
    "plt.plot(x, points, marker=\".\")\n",
    "_ = plt.xlabel(\"iterations\")\n",
    "_ = plt.ylabel(\"avg reward\")\n",
    "plt.legend([\"random\", \"policy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test (graphical simulation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_env = NumpyEnvironment(2,BOARD_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def animate(frame):\n",
    "    state = test_env.to_state()\n",
    "    original_probs = agent(\n",
    "        state\n",
    "    ) + EPSILON\n",
    "    probs = re_normalize_possible_actions(\n",
    "        state,\n",
    "        original_probs\n",
    "    )\n",
    "    actions = tf.argmax(probs, axis=-1)[...,None]\n",
    "    test_env.move(actions)\n",
    "    for board, image in zip(test_env.boards, images):\n",
    "        image.set_data(board)\n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "images = []\n",
    "for b, ax in zip(test_env.boards, axs.flatten()):\n",
    "    images.append(ax.imshow(b, origin=\"lower\"))\n",
    "anim = FuncAnimation(fig, animate, interval=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}